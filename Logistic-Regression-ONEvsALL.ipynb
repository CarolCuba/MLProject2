{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# changing labels to make one vs all\n",
    "def change_label(which_class,y_train,y_test):\n",
    "\n",
    "    samples_train = y_train.shape[0]\n",
    "    samples_test = y_test.shape[0]\n",
    "    \n",
    "    new_labels_train = np.zeros((samples_train,1))\n",
    "    new_labels_test = np.zeros((samples_test,1))\n",
    "\n",
    "    new_labels_train = np.array(y_train == which_class).astype(int)\n",
    "    new_labels_test = np.array(y_test == which_class).astype(int)\n",
    "    \n",
    "    return new_labels_train, new_labels_test\n",
    "    \n",
    "    \n",
    "'''Criando a funcao de normalização de um dataframe inteiro\n",
    "    input:\n",
    "        df: Dataframe\n",
    "    output:\n",
    "        df: Dataframe com valores normalizados\n",
    "'''\n",
    "def normalize_dataframe(df):\n",
    "    for column in df:\n",
    "        df[column] = df[column]/255\n",
    "    return df\n",
    "\n",
    "\n",
    "'''Funcao para obter as métricas de performance: precision, recall e f1_score\n",
    "    input:\n",
    "        confusion_matrix: matriz de confusão (use get_confusion_matrix() para calculá-la)\n",
    "    output:\n",
    "        precision: relação entre a quantidade de positivos preditos pela quantidade real de positivos \n",
    "        recall: relação entre a quantidade de positivos esperados pela quantidade de positivos preditos\n",
    "        f1_score: metrica para relacionar precision e recall em uma única métrica\n",
    "'''\n",
    "def get_metrics(confusion_matrix):\n",
    "    precision = get_precision(confusion_matrix)\n",
    "    recall = get_recall(confusion_matrix)\n",
    "    f1_score = get_f1_score(precision, recall)\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def print_metrics(precision, recall, f1_score):\n",
    "    precision = np.around(precision, decimals=2).reshape( precision.shape[0],1)\n",
    "    recall = np.around(recall, decimals=2).reshape( recall.shape[0],1)\n",
    "    f1_score = np.around(f1_score, decimals=2).reshape( f1_score.shape[0],1)\n",
    "    \n",
    "    average_precision = np.sum(precision)/precision.shape[0]\n",
    "    average_recall = np.sum(recall)/recall.shape[0]\n",
    "    average_f1_score = np.sum(f1_score)/f1_score.shape[0]\n",
    "    \n",
    "    print(\"\\n\\nPrecision (Pr), Recall (Re) and F1_Score (F1) of each class: \")\n",
    "    print(\"Pr   Re    F1\")\n",
    "    print(re.sub(r' *\\n *', '\\n', np.array_str(np.c_[precision, recall, f1_score]).replace('[', '').replace(']', '').strip()))\n",
    "    \n",
    "    print(\"\\n\\nAverage Precision: \", round(average_precision,2) , \"\\nAverage Recall: \", round(average_recall, 2) ,\"\\nAverage F1_Score: \", round(average_f1_score,2))\n",
    "    \n",
    "    #print(precision,\" \", recall,\" \", f1_score)\n",
    "\n",
    "def get_recall(confusion_matrix):\n",
    "    precision = np.ones((confusion_matrix.shape[0]))\n",
    "    for i in range (confusion_matrix.shape[0]):\n",
    "        tp = confusion_matrix[i,i]\n",
    "        tp_fp = np.sum(confusion_matrix[:,i])\n",
    "        \n",
    "        precision[i] = tp/tp_fp\n",
    "        \n",
    "    return precision\n",
    "\n",
    "def get_precision(confusion_matrix):\n",
    "    recall = np.ones(confusion_matrix.shape[0])\n",
    "    \n",
    "    for i in range (confusion_matrix.shape[0]):\n",
    "        tp = confusion_matrix[i,i]\n",
    "        tp_fn = np.sum(confusion_matrix[i,:])\n",
    "        \n",
    "        recall[i] = tp/tp_fn\n",
    "        \n",
    "    return recall\n",
    "\n",
    "def get_f1_score(precision, recall):\n",
    "    f1 = 2*( (precision*recall) / (precision+recall) )\n",
    "    return f1\n",
    "\n",
    "'''Funcao para calcular a matriz de confusão\n",
    "    input:\n",
    "        Y: labels corretas\n",
    "        Y_pred: labels preditas\n",
    "        classes: numéro de classes\n",
    "    output:\n",
    "        confusion_matrix: matriz de confusão\n",
    "'''\n",
    "def get_confusion_matrix(Y, Y_pred, classes):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(Y_pred.max() != 1):\n",
    "        Y_pred = binarize_labels(Y_pred,classes)\n",
    "        \n",
    "    if(Y.max() != 1 ):\n",
    "        Y = binarize_labels(Y,classes)\n",
    "    \n",
    "    confusion_matrix = np.zeros((classes,classes)).astype(int)\n",
    "    \n",
    "    for y in range (Y.shape[1]):\n",
    "        for c_pred in range (classes):\n",
    "            if(Y_pred[c_pred, y] == 1):\n",
    "                for c in range (classes):\n",
    "                    if(Y[c, y] == 1):\n",
    "                        confusion_matrix[c, c_pred]+=1\n",
    "    \n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "'''Funcao para converter um vetor de probabilidades de classes em one-hot-encoding\n",
    "    input:\n",
    "        L: vetor de probabilidade das labels\n",
    "    output:\n",
    "        Y_pred: vetor de labels (one-hot-encoding) \n",
    "    Ex: \n",
    "        Y_pred[:,1] = [0,1,0,0,0,0,0,0,0,0] quer dizer que a classe da sample 1 é 2\n",
    "'''\n",
    "def binarize_labels(L, classes):\n",
    "    samples_number = L.shape[0]\n",
    "    #classes = L.shape[0]\n",
    "    \n",
    "    Y_pred = np.array(L).reshape(1, samples_number)\n",
    "\n",
    "    y_aux = np.eye(classes)[Y_pred.astype('int32')]\n",
    "    y_aux = y_aux.T.reshape(classes, samples_number)\n",
    "\n",
    "    Y_pred = y_aux\n",
    "    \n",
    "    return Y_pred\n",
    "\n",
    "# plot image \n",
    "def plot_image(this_digit):\n",
    "    some_digit_image = this_digit.reshape(28,28)\n",
    "    plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#create sigmoid function\n",
    "def sigmoid(z):\n",
    "    s = 1.0 / (1.0 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "\n",
    "#initialize values of thetas and bias\n",
    "def initialize_parameters(dim):\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    return w,b\n",
    "\n",
    "#implement cost function and its gradient propagation\n",
    "def cost_function(w, b, X, Y):\n",
    "\n",
    "    m = X.shape[1] #quantity of samples\n",
    "    \n",
    "    z = np.dot(w.T,X)+b #hipotese without sigmoid\n",
    "    A = sigmoid(z) # applying hipotese on sigmoid, A is the result of sigmoid for each sample\n",
    "    cost = -1.0/m*np.sum(Y*np.log(A)+(1.0-Y)*np.log(1.0-A)) #find cost values for all samples\n",
    "    dw = 1.0/m*np.dot(X, (A-Y).T) #find residual of weights\n",
    "    db = 1.0/m*np.sum(A-Y) # find residual of bias\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return dw,db, cost\n",
    "\n",
    "\n",
    "#apply gradient descent\n",
    "def gradient_descent(w,b,X,Y,num_iterations,alpha, print_cost):\n",
    "    cost_array = []\n",
    "    mydict_costs={} \n",
    "    for i in range(num_iterations):\n",
    "        #call cost function\n",
    "        dw,db,cost = cost_function(w,b,X,Y)\n",
    "        # update weights and bias\n",
    "        w = w - alpha*dw\n",
    "        b = b - alpha*db\n",
    "        \n",
    "        cost_array.append(cost)\n",
    "        \n",
    "        if (print_cost == True and i%100 == 0):\n",
    "            print(\"Cost from iteration \",i,\"= \",cost,\"\\n\")\n",
    "            \n",
    "            \n",
    "    return w,b,cost_array\n",
    "\n",
    "\n",
    "#prediction\n",
    "def prediction (w,b,X,threshold):\n",
    "    samples = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,samples))\n",
    "    w = w.reshape(X.shape[0],1)\n",
    "    A = sigmoid (np.dot(w.T, X)+b)\n",
    "    return A\n",
    "\n",
    "# one vs all prediction\n",
    "def one_vs_all(w,X):\n",
    "    samples = X.shape[1]\n",
    "    weighs_qut = w.shape[0]\n",
    "    bias = w[-1]\n",
    "    weights = w[:(len(w))-1]\n",
    "    A = sigmoid (np.dot(weights.T, X)+bias)\n",
    "    \n",
    "    return A;\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataframe......\n",
      "Separating into training and validation.....\n",
      "Normalizing (This may take a couple minutes).....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Dataframe......\")\n",
    "df = pd.read_csv(\"data/fashion-mnist_train.csv\")\n",
    "\n",
    "#Separate the Training DF into Train and Validation\n",
    "msk = np.random.rand(len(df)) < 0.7 \n",
    "\n",
    "print(\"Separating into training and validation.....\")\n",
    "train_df = df[msk]\n",
    "validation_df = df[~msk]\n",
    "\n",
    "Y_train = train_df[\"label\"]\n",
    "Y_validation = validation_df[\"label\"]\n",
    "\n",
    "train_df = train_df.loc[:, train_df.columns != \"label\"]\n",
    "validation_df = validation_df.loc[:, validation_df.columns != \"label\"]\n",
    "\n",
    "#test_df = pd.read_csv(\"data/fashion-mnist_test.csv\")\n",
    "\n",
    "print(\"Normalizing (This may take a couple minutes).....\")\n",
    "normalized_train_df = normalize_dataframe(train_df)\n",
    "normalized_validation_df = normalize_dataframe(validation_df)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig class  0\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.1209759604452918 \n",
      "\n",
      "Cost from iteration  200 =  0.11547497490981043 \n",
      "\n",
      "Cost from iteration  300 =  0.11246451156513441 \n",
      "\n",
      "Cost from iteration  400 =  0.11043221049531557 \n",
      "\n",
      "Cost from iteration  500 =  0.10894196278551203 \n",
      "\n",
      "Cost from iteration  600 =  0.10779497364627443 \n",
      "\n",
      "Cost from iteration  700 =  0.10688103292817885 \n",
      "\n",
      "Cost from iteration  800 =  0.10613264358500807 \n",
      "\n",
      "Cost from iteration  900 =  0.1055058691093985 \n",
      "\n",
      "Cost from iteration  1000 =  0.10497086095024231 \n",
      "\n",
      "Cost from iteration  1100 =  0.10450667294175309 \n",
      "\n",
      "Cost from iteration  1200 =  0.10409821927930518 \n",
      "\n",
      "Cost from iteration  1300 =  0.10373439647453411 \n",
      "\n",
      "Cost from iteration  1400 =  0.10340687751965313 \n",
      "\n",
      "Cost from iteration  1500 =  0.10310931320963503 \n",
      "\n",
      "Cost from iteration  1600 =  0.10283678952096957 \n",
      "\n",
      "Cost from iteration  1700 =  0.10258545097172625 \n",
      "\n",
      "Cost from iteration  1800 =  0.10235223430616787 \n",
      "\n",
      "Cost from iteration  1900 =  0.10213467709007283 \n",
      "\n",
      "Trainig class  1\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.048084833584655776 \n",
      "\n",
      "Cost from iteration  200 =  0.040227805932043136 \n",
      "\n",
      "Cost from iteration  300 =  0.036396159210759484 \n",
      "\n",
      "Cost from iteration  400 =  0.03396459115458094 \n",
      "\n",
      "Cost from iteration  500 =  0.032235321458113704 \n",
      "\n",
      "Cost from iteration  600 =  0.030921009321171988 \n",
      "\n",
      "Cost from iteration  700 =  0.029876380100172385 \n",
      "\n",
      "Cost from iteration  800 =  0.029018631882073938 \n",
      "\n",
      "Cost from iteration  900 =  0.02829663963962592 \n",
      "\n",
      "Cost from iteration  1000 =  0.027676934411548 \n",
      "\n",
      "Cost from iteration  1100 =  0.027136588244372893 \n",
      "\n",
      "Cost from iteration  1200 =  0.026659309679464765 \n",
      "\n",
      "Cost from iteration  1300 =  0.026233167931589276 \n",
      "\n",
      "Cost from iteration  1400 =  0.025849200383713404 \n",
      "\n",
      "Cost from iteration  1500 =  0.025500525671289343 \n",
      "\n",
      "Cost from iteration  1600 =  0.025181759429535617 \n",
      "\n",
      "Cost from iteration  1700 =  0.0248886182214053 \n",
      "\n",
      "Cost from iteration  1800 =  0.024617644298228426 \n",
      "\n",
      "Cost from iteration  1900 =  0.02436601011833852 \n",
      "\n",
      "Trainig class  2\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.20899492901940586 \n",
      "\n",
      "Cost from iteration  200 =  0.18586078110147441 \n",
      "\n",
      "Cost from iteration  300 =  0.1749092405303956 \n",
      "\n",
      "Cost from iteration  400 =  0.16835317687969445 \n",
      "\n",
      "Cost from iteration  500 =  0.1638830006640793 \n",
      "\n",
      "Cost from iteration  600 =  0.16057085629991003 \n",
      "\n",
      "Cost from iteration  700 =  0.1579757253797957 \n",
      "\n",
      "Cost from iteration  800 =  0.15586141659523217 \n",
      "\n",
      "Cost from iteration  900 =  0.15408976829231405 \n",
      "\n",
      "Cost from iteration  1000 =  0.15257406696915057 \n",
      "\n",
      "Cost from iteration  1100 =  0.1512565943908484 \n",
      "\n",
      "Cost from iteration  1200 =  0.1500969880268608 \n",
      "\n",
      "Cost from iteration  1300 =  0.14906584636308773 \n",
      "\n",
      "Cost from iteration  1400 =  0.14814103254038674 \n",
      "\n",
      "Cost from iteration  1500 =  0.14730543435619584 \n",
      "\n",
      "Cost from iteration  1600 =  0.14654554458536004 \n",
      "\n",
      "Cost from iteration  1700 =  0.14585052254362837 \n",
      "\n",
      "Cost from iteration  1800 =  0.14521154952091134 \n",
      "\n",
      "Cost from iteration  1900 =  0.14462137089819774 \n",
      "\n",
      "Trainig class  3\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.11161382859341612 \n",
      "\n",
      "Cost from iteration  200 =  0.10161780313596448 \n",
      "\n",
      "Cost from iteration  300 =  0.09755330267264876 \n",
      "\n",
      "Cost from iteration  400 =  0.09517239998318765 \n",
      "\n",
      "Cost from iteration  500 =  0.0935158876654576 \n",
      "\n",
      "Cost from iteration  600 =  0.09224950216427835 \n",
      "\n",
      "Cost from iteration  700 =  0.09122592998043645 \n",
      "\n",
      "Cost from iteration  800 =  0.09036876790901308 \n",
      "\n",
      "Cost from iteration  900 =  0.08963330159211215 \n",
      "\n",
      "Cost from iteration  1000 =  0.0889909083060162 \n",
      "\n",
      "Cost from iteration  1100 =  0.0884220221806142 \n",
      "\n",
      "Cost from iteration  1200 =  0.08791261060628949 \n",
      "\n",
      "Cost from iteration  1300 =  0.0874522448101086 \n",
      "\n",
      "Cost from iteration  1400 =  0.08703296119064215 \n",
      "\n",
      "Cost from iteration  1500 =  0.08664854680024359 \n",
      "\n",
      "Cost from iteration  1600 =  0.08629406843982688 \n",
      "\n",
      "Cost from iteration  1700 =  0.08596555008181574 \n",
      "\n",
      "Cost from iteration  1800 =  0.08565974508404084 \n",
      "\n",
      "Cost from iteration  1900 =  0.08537397140760532 \n",
      "\n",
      "Trainig class  4\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.28258729135183813 \n",
      "\n",
      "Cost from iteration  200 =  0.2085425564046607 \n",
      "\n",
      "Cost from iteration  300 =  0.17732449699398806 \n",
      "\n",
      "Cost from iteration  400 =  0.1621638318542293 \n",
      "\n",
      "Cost from iteration  500 =  0.15398809328162225 \n",
      "\n",
      "Cost from iteration  600 =  0.1489104822364513 \n",
      "\n",
      "Cost from iteration  700 =  0.14530767570883865 \n",
      "\n",
      "Cost from iteration  800 =  0.14249643147110377 \n",
      "\n",
      "Cost from iteration  900 =  0.14017042317478434 \n",
      "\n",
      "Cost from iteration  1000 =  0.13817682743726556 \n",
      "\n",
      "Cost from iteration  1100 =  0.13642960886343236 \n",
      "\n",
      "Cost from iteration  1200 =  0.13487486394287782 \n",
      "\n",
      "Cost from iteration  1300 =  0.1334759532039371 \n",
      "\n",
      "Cost from iteration  1400 =  0.13220648089649537 \n",
      "\n",
      "Cost from iteration  1500 =  0.13104662869145178 \n",
      "\n",
      "Cost from iteration  1600 =  0.12998106232395973 \n",
      "\n",
      "Cost from iteration  1700 =  0.1289976495542125 \n",
      "\n",
      "Cost from iteration  1800 =  0.12808663479141466 \n",
      "\n",
      "Cost from iteration  1900 =  0.12724009210325526 \n",
      "\n",
      "Trainig class  5\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.10035778686140366 \n",
      "\n",
      "Cost from iteration  200 =  0.08239813157021826 \n",
      "\n",
      "Cost from iteration  300 =  0.07341923060768143 \n",
      "\n",
      "Cost from iteration  400 =  0.0678430001594512 \n",
      "\n",
      "Cost from iteration  500 =  0.06396774024555466 \n",
      "\n",
      "Cost from iteration  600 =  0.06107915994827591 \n",
      "\n",
      "Cost from iteration  700 =  0.058820445013236654 \n",
      "\n",
      "Cost from iteration  800 =  0.05699186336217475 \n",
      "\n",
      "Cost from iteration  900 =  0.05547212107300149 \n",
      "\n",
      "Cost from iteration  1000 =  0.054182879117601994 \n",
      "\n",
      "Cost from iteration  1100 =  0.05307103821016076 \n",
      "\n",
      "Cost from iteration  1200 =  0.052099180250699755 \n",
      "\n",
      "Cost from iteration  1300 =  0.05124008165315105 \n",
      "\n",
      "Cost from iteration  1400 =  0.050473400383198815 \n",
      "\n",
      "Cost from iteration  1500 =  0.04978358913632052 \n",
      "\n",
      "Cost from iteration  1600 =  0.04915853287651511 \n",
      "\n",
      "Cost from iteration  1700 =  0.04858863149537602 \n",
      "\n",
      "Cost from iteration  1800 =  0.048066165454463634 \n",
      "\n",
      "Cost from iteration  1900 =  0.047584846742412694 \n",
      "\n",
      "Trainig class  6\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.21513981044686253 \n",
      "\n",
      "Cost from iteration  200 =  0.24608558665420432 \n",
      "\n",
      "Cost from iteration  300 =  0.27181937796233163 \n",
      "\n",
      "Cost from iteration  400 =  0.2769485892291457 \n",
      "\n",
      "Cost from iteration  500 =  0.26487672969925635 \n",
      "\n",
      "Cost from iteration  600 =  0.25580904076292443 \n",
      "\n",
      "Cost from iteration  700 =  0.24881515215151695 \n",
      "\n",
      "Cost from iteration  800 =  0.2433036132173327 \n",
      "\n",
      "Cost from iteration  900 =  0.23887668344014307 \n",
      "\n",
      "Cost from iteration  1000 =  0.23525885121317805 \n",
      "\n",
      "Cost from iteration  1100 =  0.2322552035270938 \n",
      "\n",
      "Cost from iteration  1200 =  0.2297253465256082 \n",
      "\n",
      "Cost from iteration  1300 =  0.227566489721817 \n",
      "\n",
      "Cost from iteration  1400 =  0.22570222525820904 \n",
      "\n",
      "Cost from iteration  1500 =  0.22407494711746115 \n",
      "\n",
      "Cost from iteration  1600 =  0.2226406442259822 \n",
      "\n",
      "Cost from iteration  1700 =  0.22136526927523067 \n",
      "\n",
      "Cost from iteration  1800 =  0.22022217057672958 \n",
      "\n",
      "Cost from iteration  1900 =  0.2191902519071943 \n",
      "\n",
      "Trainig class  7\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.08866444385577217 \n",
      "\n",
      "Cost from iteration  200 =  0.07679354472978046 \n",
      "\n",
      "Cost from iteration  300 =  0.07056362435988009 \n",
      "\n",
      "Cost from iteration  400 =  0.06653881892722255 \n",
      "\n",
      "Cost from iteration  500 =  0.06365668312449059 \n",
      "\n",
      "Cost from iteration  600 =  0.06146064463709964 \n",
      "\n",
      "Cost from iteration  700 =  0.05971593715778105 \n",
      "\n",
      "Cost from iteration  800 =  0.058287194212429554 \n",
      "\n",
      "Cost from iteration  900 =  0.05708988844657071 \n",
      "\n",
      "Cost from iteration  1000 =  0.05606805660424633 \n",
      "\n",
      "Cost from iteration  1100 =  0.05518294960041502 \n",
      "\n",
      "Cost from iteration  1200 =  0.0544067692280906 \n",
      "\n",
      "Cost from iteration  1300 =  0.05371898974376674 \n",
      "\n",
      "Cost from iteration  1400 =  0.053104087137335984 \n",
      "\n",
      "Cost from iteration  1500 =  0.05255007903351685 \n",
      "\n",
      "Cost from iteration  1600 =  0.0520475533679514 \n",
      "\n",
      "Cost from iteration  1700 =  0.05158900334959076 \n",
      "\n",
      "Cost from iteration  1800 =  0.0511683607455416 \n",
      "\n",
      "Cost from iteration  1900 =  0.05078066124949553 \n",
      "\n",
      "Trainig class  8\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost from iteration  100 =  0.08223469134149816 \n",
      "\n",
      "Cost from iteration  200 =  0.07028396898159565 \n",
      "\n",
      "Cost from iteration  300 =  0.06490380725244058 \n",
      "\n",
      "Cost from iteration  400 =  0.061465807893482896 \n",
      "\n",
      "Cost from iteration  500 =  0.05895429587006626 \n",
      "\n",
      "Cost from iteration  600 =  0.05699653830496318 \n",
      "\n",
      "Cost from iteration  700 =  0.05541237456826529 \n",
      "\n",
      "Cost from iteration  800 =  0.05409849094261796 \n",
      "\n",
      "Cost from iteration  900 =  0.05298878483957185 \n",
      "\n",
      "Cost from iteration  1000 =  0.052037865705536125 \n",
      "\n",
      "Cost from iteration  1100 =  0.05121308463698501 \n",
      "\n",
      "Cost from iteration  1200 =  0.05049019887524378 \n",
      "\n",
      "Cost from iteration  1300 =  0.0498507848054861 \n",
      "\n",
      "Cost from iteration  1400 =  0.0492805847443649 \n",
      "\n",
      "Cost from iteration  1500 =  0.048768397576630096 \n",
      "\n",
      "Cost from iteration  1600 =  0.048305308048110854 \n",
      "\n",
      "Cost from iteration  1700 =  0.04788413750414706 \n",
      "\n",
      "Cost from iteration  1800 =  0.04749904462214292 \n",
      "\n",
      "Cost from iteration  1900 =  0.04714523042499829 \n",
      "\n",
      "Trainig class  9\n",
      "Cost from iteration  0 =  0.6931471805599454 \n",
      "\n",
      "Cost from iteration  100 =  0.07891932166744497 \n",
      "\n",
      "Cost from iteration  200 =  0.06638544890119817 \n",
      "\n",
      "Cost from iteration  300 =  0.060155053810707 \n",
      "\n",
      "Cost from iteration  400 =  0.056083335358294795 \n",
      "\n",
      "Cost from iteration  500 =  0.053098982954050564 \n",
      "\n",
      "Cost from iteration  600 =  0.05077176484538677 \n",
      "\n",
      "Cost from iteration  700 =  0.0488854676518354 \n",
      "\n",
      "Cost from iteration  800 =  0.04731543016563063 \n",
      "\n",
      "Cost from iteration  900 =  0.04598285120612128 \n",
      "\n",
      "Cost from iteration  1000 =  0.0448345715812479 \n",
      "\n",
      "Cost from iteration  1100 =  0.043832971016075424 \n",
      "\n",
      "Cost from iteration  1200 =  0.04295043684991175 \n",
      "\n",
      "Cost from iteration  1300 =  0.04216611368404063 \n",
      "\n",
      "Cost from iteration  1400 =  0.04146388320356082 \n",
      "\n",
      "Cost from iteration  1500 =  0.04083105041550283 \n",
      "\n",
      "Cost from iteration  1600 =  0.04025745693990196 \n",
      "\n",
      "Cost from iteration  1700 =  0.039734863744608946 \n",
      "\n",
      "Cost from iteration  1800 =  0.03925651011209669 \n",
      "\n",
      "Cost from iteration  1900 =  0.03881679145683726 \n",
      "\n",
      "--- 808.7985575199127 time 1 seconds ---\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "X_train = normalized_train_df.T\n",
    "X_test = normalized_validation_df.T\n",
    "\n",
    "\n",
    "i = 0;\n",
    "dim_train = X_train.shape[0]\n",
    "dim_test = X_test.shape[0]\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "y_train = Y_train\n",
    "y_test = Y_validation\n",
    "\n",
    "classifiers = {} #dicionarios de classificadores treinados\n",
    "#probabilities = np.zeros((num_classes,dim_test))\n",
    "probabilities = []\n",
    "start_time1 = time.time()\n",
    "while i < num_classes:\n",
    "    print(\"Trainig class \", i)\n",
    "    new_label_train, new_label_test = change_label(i,y_train,y_test)\n",
    "    ws, bs = initialize_parameters(dim_train) \n",
    "    #Mude o change cost para True para verbose dos custos\n",
    "    w,b,costs = gradient_descent(ws,bs,X_train,new_label_train,500,0.3\n",
    "                                 ,print_cost=True) # pesos e bias treinados\n",
    "    treined_parameters = (np.append(w,b)).reshape(dim_train+1,1)  # concatenate weights\n",
    "    classifiers.update({i:treined_parameters})\n",
    "    i = i+1\n",
    "\n",
    "print(\"--- %s time 1 seconds ---\" % (time.time() - start_time1))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1499    7   44   77    9    3   59    0   23    2]\n",
      " [   7 1689   24   48    4    0    2    0    3    0]\n",
      " [  27    4 1470   17  173    2   35    0   26    0]\n",
      " [  79   30   40 1552   53    1   18    1    8    0]\n",
      " [   5    2  290   89 1370    0   71    0   18    0]\n",
      " [   2    0    1    1    0 1640    2   93   16   45]\n",
      " [ 348    6  368   88  228    2  723    1   46    0]\n",
      " [   0    0    0    0    0   67    0 1614    4   76]\n",
      " [   6    0   28   14    9   11   12   12 1778    2]\n",
      " [   0    1    0    1    0   19    0   70    3 1649]]\n",
      "\n",
      "\n",
      "Precision (Pr), Recall (Re) and F1_Score (F1) of each class: \n",
      "Pr   Re    F1\n",
      "0.87 0.76 0.81\n",
      "0.95 0.97 0.96\n",
      "0.84 0.65 0.73\n",
      "0.87 0.82 0.85\n",
      "0.74 0.74 0.74\n",
      "0.91 0.94 0.93\n",
      "0.4  0.78 0.53\n",
      "0.92 0.9  0.91\n",
      "0.95 0.92 0.94\n",
      "0.95 0.93 0.94\n",
      "\n",
      "\n",
      "Average Precision:  0.84 \n",
      "Average Recall:  0.84 \n",
      "Average F1_Score:  0.83\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "\n",
    "probabilities = []\n",
    "#compute probabilities for each class\n",
    "while j < num_classes:\n",
    "    prob = one_vs_all(classifiers.get(j),X_test)\n",
    "    #probabilities[:][:j] = prob\n",
    "    #print(prob.shape)\n",
    "    probabilities.append(prob)\n",
    "    #print(np.array(probabilities).shape)\n",
    "    j = j+1\n",
    "\n",
    "k = 0\n",
    "aux_array = np.zeros(num_classes)\n",
    "aux_array_2 = np.zeros((num_classes, X_test.shape[1]))\n",
    "#print(np.array(aux_array_2).shape)\n",
    "prediction_array = []\n",
    "y = y_test\n",
    "\n",
    "for c in range (num_classes):\n",
    "    aux_array_2[c] = probabilities[c][0]\n",
    "\n",
    "final = np.array(np.argmax(aux_array_2, axis=0))\n",
    "\n",
    "y_test_new = y_test.T\n",
    "\n",
    "#print(\"oi\", final.shape)\n",
    "\n",
    "confusion_matrix = get_confusion_matrix(y_test_new,final, 10)\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "precision, recall, f1_score = get_metrics(confusion_matrix)\n",
    "\n",
    "print_metrics(precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
